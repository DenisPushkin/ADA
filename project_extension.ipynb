{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You are what you eat - Relating Demographic Data to Food Consumption Habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns  # needed for heatmap\n",
    "from os.path import join\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "plt.rcParams['figure.figsize'] = [7, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths for data\n",
    "FOLDER_PATH = 'data'\n",
    "PURCHASES_PATH = 'area_level_purchases'\n",
    "OSWARD_GROCERY = 'year_osward_grocery.csv'\n",
    "WARD_ATLAS = 'ward-atlas-data.csv'\n",
    "\n",
    "ward_data_path = join(FOLDER_PATH, PURCHASES_PATH, OSWARD_GROCERY)\n",
    "atlas_data_path = join(FOLDER_PATH, WARD_ATLAS)\n",
    "\n",
    "# load the data sets\n",
    "df_ward = pd.read_csv(ward_data_path, sep=',', index_col=0)\n",
    "df_atlas = pd.read_csv(atlas_data_path, sep=',', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df_atlas` data set looks very messy. Row 0 contains info about the data. For every ward and demographic marker yearly (from 2001 to 2006) values exist in columns. According to the [source](https://data.london.gov.uk/dataset/ward-profiles-and-atlas) this data set was collected in September 2015 with the most up-to-date information available. Thus, for many markers, the last available information dates to 2015 or even earlier (e.g. 2013). Our first step is to clean the data set from outdated columns and only keep the most up-to-date demographic markers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated by the title, we are interested in demographic markers which help classifying different classes of people. These are for example gender, religion, ethnicity, wealth, age. Thus, in the following, we drop columns which we deem not helpful in classifying people into groups. We acknowledge that this process can be rather biased, however, as the data set has 946 columns, we see the need to reduce the data set's complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_data(df_atlas):\n",
    "    # clean age (columns after 2013 are projections, therefore keep 2013 columns)\n",
    "    cond = df_atlas.columns.str.startswith('Population and Age') & ~df_atlas.columns.str.contains('2013')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # drop absolute population values\n",
    "    df_atlas = df_atlas.drop(['Population and Age; Population Estimates and Projections; 2013',\n",
    "                   'Population and Age; Aged 0-15; 2013',\n",
    "                   'Population and Age; Aged 16-64; 2013',\n",
    "                   'Population and Age; Aged 65+; 2013',\n",
    "                   'Population and Age; All ages; 2013',\n",
    "                   'Population and Age; Mean age; 2013',\n",
    "                   'Population and Age; Median age; 2013'], axis=1)\n",
    "    # delete population density\n",
    "    cond = df_atlas.columns.str.startswith('Area and Density')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete the 18 ethnic groups for now, as they add complexity\n",
    "    cond = df_atlas.columns.str.startswith('Diversity; Ethnic Group 18 groups')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete household language (of no interest) \n",
    "    cond = df_atlas.columns.str.startswith('Diversity; Household Language - 2011 Census')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete household composition data\n",
    "    cond = df_atlas.columns.str.startswith('Household composition')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete household repossesion\n",
    "    cond = df_atlas.columns.str.startswith('Home repossessions')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete outdated birth and death markers\n",
    "    cond = df_atlas.columns.str.startswith('Births and deaths')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete outdated life expectancy\n",
    "    cond = df_atlas.columns.str.startswith('Life Expectancy')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete outdated housing markers\n",
    "    cond = df_atlas.columns.str.startswith('Housing type and Tenure')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    cond = df_atlas.columns.str.startswith('House Prices')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete tax related data (not of interest)\n",
    "    cond = df_atlas.columns.str.startswith('Dwellings and Council tax')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete dwelling data which is not of interest\n",
    "    cond = df_atlas.columns.str.startswith('Property Type') | df_atlas.columns.str.startswith('Size of dwellings') | df_atlas.columns.str.startswith('Property build period')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete outdated income data\n",
    "    cond = df_atlas.columns.str.startswith('Household Income') & ~df_atlas.columns.str.contains('2012/13')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # outdated employment data\n",
    "    cond = df_atlas.columns.str.startswith('Employment')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete benefits claimants and jobseekers allowance\n",
    "    cond = df_atlas.columns.str.startswith('Benefits claimants') | df_atlas.columns.str.startswith('Jobseekers Allowance')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete out of work families\n",
    "    cond = df_atlas.columns.str.startswith('Out-of-Work Families')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # outdated poverty\n",
    "    cond = df_atlas.columns.str.startswith('Children in Poverty')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # outdated \"intelligence\" scores\n",
    "    cond = df_atlas.columns.str.startswith('GCSE')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    cond = df_atlas.columns.str.startswith('A-Level Point Scores')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # pupil abscence not if interest\n",
    "    cond = df_atlas.columns.str.startswith('Pupil Absence')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # individual crimes not of interest, only crime rate\n",
    "    cond = df_atlas.columns.str.startswith('Crime') # & ~df_atlas.columns.str.contains('Total crime rate; 2014/15')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # further columns not of interest\n",
    "    cond = df_atlas.columns.str.startswith('Fires') | df_atlas.columns.str.startswith('Ambulance') \\\n",
    "    | df_atlas.columns.str.startswith('Binge Drinking') | df_atlas.columns.str.startswith('Road Casualties') \\\n",
    "    | df_atlas.columns.str.startswith('Air Emissions') | df_atlas.columns.str.startswith('Land Use') \\\n",
    "    | df_atlas.columns.str.startswith('Access to green space and nature') | df_atlas.columns.str.startswith('Public Transport Accessibility')\\\n",
    "    | df_atlas.columns.str.startswith('Car access') | df_atlas.columns.str.startswith('Travel to work by bicycle') \\\n",
    "    | df_atlas.columns.str.startswith('Workplace employment') | df_atlas.columns.str.startswith('Nat Insurance No. registrations') \\\n",
    "    | df_atlas.columns.str.startswith('Election turnout')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # obesity already available in cleaned format\n",
    "    cond = df_atlas.columns.str.startswith('Childhood Obesity Prevalence')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    # delete old indices of deprivation\n",
    "    cond = df_atlas.columns.str.startswith('Indices of Deprivation') & ~df_atlas.columns.str.contains('2010')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    cond = df_atlas.columns.str.startswith('Indices of Deprivation') & ~df_atlas.columns.str.endswith('Average Score; 2010')\n",
    "    df_atlas = df_atlas.loc[:, ~cond]\n",
    "    \n",
    "    df_atlas.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    df_atlas.drop(df_atlas.index[-3:], inplace=True)\n",
    "    df_atlas.drop(df_atlas.index[0], inplace=True)\n",
    "    return df_atlas\n",
    "\n",
    "df_atlas = drop_redundant_data(df_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 4 columns seem to have a wrong name\n",
    "df_atlas.rename(columns={'Unnamed: 1': 'New Code', 'Unnamed: 2': 'Borough', \n",
    "                         'Unnamed: 3': 'Names'}, inplace=True)\n",
    "\n",
    "# very long column names, rename columns to more concise names\n",
    "import re\n",
    "rename_map = {name: re.sub('.*; ', '', name) for name in df_atlas.columns.values}\n",
    "# after inspection 'Household Income; Median Modelled Household income (£); 2012/13',\n",
    "# 'Household Income; Mean Modelled Household income (£); 2012/13',\n",
    "# 'Happiness and Well-being; Subjective well-being average score, 2011/12 and 2012/13; ',\n",
    "# and 'Indices of Deprivation; Average Score; 2010' have been replaced too much, manually add those column names\n",
    "rename_map['Household Income; Median Modelled Household income (£); 2012/13'] = 'Household Income Mean'\n",
    "rename_map['Household Income; Mean Modelled Household income (£); 2012/13'] = 'Household Income Median'\n",
    "rename_map['Happiness and Well-being; Subjective well-being average score, 2011/12 and 2012/13; '] = 'Well-Being'\n",
    "rename_map['Indices of Deprivation; Average Score; 2010'] = 'IOD AVG'\n",
    "df_atlas.rename(columns=rename_map, inplace=True)\n",
    "                         \n",
    "df_atlas.rename(columns={'% No qualifications': 'No qualifications', \n",
    "                         '% Highest level of qualification: Level 1 qualifications': 'Level 1 qualifications', \n",
    "                         '% Highest level of qualification: Level 2 qualifications': 'Level 2 qualifications', \n",
    "                         '% Highest level of qualification: Apprenticeship': 'Apprenticeship qualifications', \n",
    "                         '% Highest level of qualification: Level 3 qualifications': 'Level 3 qualifications', \n",
    "                         '% Highest level of qualification: Level 4 qualifications and above': 'Level >=4 qualifications',\n",
    "                         '% Highest level of qualification: Other qualifications': 'Other qualifications', \n",
    "                         '% People with Bad or Very Bad Health': 'Bad Health',\n",
    "                         '% People whose Day-to-day activities are limited a lot': 'Limited activities'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to numeric conversion\n",
    "df_atlas.loc[:, 'Aged 0-15':] = df_atlas.loc[:, 'Aged 0-15':].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cols = ['Aged 0-15', 'Aged 16-64', 'Aged 65+'] #sum to 1\n",
    "ethnicities_cols = ['White', 'Mixed', 'Asian or Asian British', 'Black or Black British', 'Other'] #sum to 1\n",
    "religion_cols = ['Christian', 'Buddhist', 'Hindu', 'Jewish', 'Muslim', 'Sikh',\n",
    "       'No religion', 'Other religions', 'Religion not stated'] # sum to 1\n",
    "born_cols = ['Born in UK', 'Not Born in UK'] # sum to 1\n",
    "wealth_cols = ['Household Income Median', 'IOD AVG'] #'Well-Being'\n",
    "qualilication_cols = ['No qualifications', 'Level 1 qualifications', 'Level 2 qualifications',\n",
    "       'Apprenticeship qualifications', 'Level 3 qualifications',\n",
    "       'Level >=4 qualifications', 'Other qualifications'] # sum to 1 \n",
    "disability_cols = ['Bad Health', 'Limited activities']\n",
    "all_features = age_cols + ethnicities_cols + religion_cols + born_cols + wealth_cols + qualilication_cols + disability_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    total = df[cols].sum(axis=1)\n",
    "    df[cols] = df[cols].div(total, axis=0)\n",
    "    return df\n",
    "\n",
    "def standartize(df, cols):\n",
    "    means = df[cols].mean()\n",
    "    stds = df[cols].std()\n",
    "    df[cols] = (df[cols] - means) / stds\n",
    "    return df\n",
    "\n",
    "def min_max_scaling(df, cols):\n",
    "    mins = df[cols].min()\n",
    "    maxs = df[cols].max()\n",
    "    df[cols] = (df[cols] - mins) / (maxs - mins)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "df_atlas[age_cols] /= 100\n",
    "df_atlas = normalize(df_atlas, ethnicities_cols)\n",
    "df_atlas = normalize(df_atlas, religion_cols)\n",
    "df_atlas = normalize(df_atlas, born_cols)\n",
    "df_atlas[qualilication_cols] /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for cols in [age_cols, ethnicities_cols, religion_cols, born_cols, qualilication_cols]:\n",
    "    print(any(np.abs(df_atlas[cols].sum(axis=1) - 1) > 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "df_atlas['Household Income Median'].hist(bins=50, ax=ax[0])\n",
    "(np.log(df_atlas['Household Income Median'])).hist(bins=50, ax=ax[1])\n",
    "plt.show()\n",
    "#haivy-tailed, makes sense to apply log transform before min-max rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "df_atlas['IOD AVG'].hist(bins=50, ax=ax[0])\n",
    "(np.log(df_atlas['IOD AVG'])).hist(bins=50, ax=ax[1])\n",
    "plt.show()\n",
    "#no sense to apply log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas['Household Income Median'] = df_atlas['Household Income Median'].apply(np.log)\n",
    "df_atlas = standartize(df_atlas, wealth_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "df_atlas['Bad Health'].hist(bins=50, ax=ax[0])\n",
    "(np.log(df_atlas['Bad Health'])).hist(bins=50, ax=ax[1])\n",
    "plt.show()\n",
    "#no sense to apply log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "df_atlas['Limited activities'].hist(bins=50, ax=ax[0])\n",
    "(np.log(df_atlas['Limited activities'])).hist(bins=50, ax=ax[1])\n",
    "plt.show()\n",
    "#no sense to apply log transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas = standartize(df_atlas, disability_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices of deprivation measure how deprived an area is [source](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/464597/English_Indices_of_Deprivation_2015_-_Research_Report.pdf). In essence, these indicators indicate how impoverished an area is. The linked documents lists the meaning of the different indices. *The average score measure summarises the average level of deprivation across the higher-level area,based on the scores of the Lower-layer Super Output Areas in the area.* Therefore, we decided to keep only this measure, as we are interested in an indicator of \"average impoverishment\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['weight', 'weight_perc2.5', 'weight_perc25', 'weight_perc50',\n",
       "       'weight_perc75', 'weight_perc97.5', 'weight_std', 'weight_ci95',\n",
       "       'volume', 'volume_perc2.5', 'volume_perc25', 'volume_perc50',\n",
       "       'volume_perc75', 'volume_perc97.5', 'volume_std', 'volume_ci95',\n",
       "       'fat', 'fat_perc2.5', 'fat_perc25', 'fat_perc50', 'fat_perc75',\n",
       "       'fat_perc97.5', 'fat_std', 'fat_ci95', 'saturate',\n",
       "       'saturate_perc2.5', 'saturate_perc25', 'saturate_perc50',\n",
       "       'saturate_perc75', 'saturate_perc97.5', 'saturate_std',\n",
       "       'saturate_ci95', 'salt', 'salt_perc2.5', 'salt_perc25',\n",
       "       'salt_perc50', 'salt_perc75', 'salt_perc97.5', 'salt_std',\n",
       "       'salt_ci95', 'sugar', 'sugar_perc2.5', 'sugar_perc25',\n",
       "       'sugar_perc50', 'sugar_perc75', 'sugar_perc97.5', 'sugar_std',\n",
       "       'sugar_ci95', 'protein', 'protein_perc2.5', 'protein_perc25',\n",
       "       'protein_perc50', 'protein_perc75', 'protein_perc97.5',\n",
       "       'protein_std', 'protein_ci95', 'carb', 'carb_perc2.5',\n",
       "       'carb_perc25', 'carb_perc50', 'carb_perc75', 'carb_perc97.5',\n",
       "       'carb_std', 'carb_ci95', 'fibre', 'fibre_perc2.5', 'fibre_perc25',\n",
       "       'fibre_perc50', 'fibre_perc75', 'fibre_perc97.5', 'fibre_std',\n",
       "       'fibre_ci95', 'alcohol', 'alcohol_perc2.5', 'alcohol_perc25',\n",
       "       'alcohol_perc50', 'alcohol_perc75', 'alcohol_perc97.5',\n",
       "       'alcohol_std', 'alcohol_ci95', 'energy_fat', 'energy_fat_perc2.5',\n",
       "       'energy_fat_perc25', 'energy_fat_perc50', 'energy_fat_perc75',\n",
       "       'energy_fat_perc97.5', 'energy_fat_std', 'energy_fat_ci95',\n",
       "       'energy_saturate', 'energy_saturate_perc2.5',\n",
       "       'energy_saturate_perc25', 'energy_saturate_perc50',\n",
       "       'energy_saturate_perc75', 'energy_saturate_perc97.5',\n",
       "       'energy_saturate_std', 'energy_saturate_ci95', 'energy_sugar',\n",
       "       'energy_sugar_perc2.5', 'energy_sugar_perc25',\n",
       "       'energy_sugar_perc50', 'energy_sugar_perc75',\n",
       "       'energy_sugar_perc97.5', 'energy_sugar_std', 'energy_sugar_ci95',\n",
       "       'energy_protein', 'energy_protein_perc2.5',\n",
       "       'energy_protein_perc25', 'energy_protein_perc50',\n",
       "       'energy_protein_perc75', 'energy_protein_perc97.5',\n",
       "       'energy_protein_std', 'energy_protein_ci95', 'energy_carb',\n",
       "       'energy_carb_perc2.5', 'energy_carb_perc25', 'energy_carb_perc50',\n",
       "       'energy_carb_perc75', 'energy_carb_perc97.5', 'energy_carb_std',\n",
       "       'energy_carb_ci95', 'energy_fibre', 'energy_fibre_perc2.5',\n",
       "       'energy_fibre_perc25', 'energy_fibre_perc50',\n",
       "       'energy_fibre_perc75', 'energy_fibre_perc97.5', 'energy_fibre_std',\n",
       "       'energy_fibre_ci95', 'energy_alcohol', 'energy_alcohol_perc2.5',\n",
       "       'energy_alcohol_perc25', 'energy_alcohol_perc50',\n",
       "       'energy_alcohol_perc75', 'energy_alcohol_perc97.5',\n",
       "       'energy_alcohol_std', 'energy_alcohol_ci95', 'energy_tot',\n",
       "       'energy_tot_perc2.5', 'energy_tot_perc25', 'energy_tot_perc50',\n",
       "       'energy_tot_perc75', 'energy_tot_perc97.5', 'energy_tot_std',\n",
       "       'energy_tot_ci95', 'f_energy_fat', 'f_energy_saturate',\n",
       "       'f_energy_sugar', 'f_energy_protein', 'f_energy_carb',\n",
       "       'f_energy_fibre', 'f_energy_alcohol', 'energy_density',\n",
       "       'h_nutrients_weight', 'h_nutrients_weight_norm',\n",
       "       'h_nutrients_calories', 'h_nutrients_calories_norm', 'f_beer',\n",
       "       'f_dairy', 'f_eggs', 'f_fats_oils', 'f_fish', 'f_fruit_veg',\n",
       "       'f_grains', 'f_meat_red', 'f_poultry', 'f_readymade', 'f_sauces',\n",
       "       'f_soft_drinks', 'f_spirits', 'f_sweets', 'f_tea_coffee',\n",
       "       'f_water', 'f_wine', 'f_dairy_weight', 'f_eggs_weight',\n",
       "       'f_fats_oils_weight', 'f_fish_weight', 'f_fruit_veg_weight',\n",
       "       'f_grains_weight', 'f_meat_red_weight', 'f_poultry_weight',\n",
       "       'f_readymade_weight', 'f_sauces_weight', 'f_sweets_weight',\n",
       "       'h_items', 'h_items_norm', 'h_items_weight', 'h_items_weight_norm',\n",
       "       'representativeness_norm', 'transaction_days', 'num_transactions',\n",
       "       'man_day', 'population', 'male', 'female', 'age_0_17', 'age_18_64',\n",
       "       'age_65+', 'avg_age', 'area_sq_km', 'people_per_sq_km'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ward.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_cols = ['weight', 'volume', 'fat', 'saturate', 'salt', 'sugar', 'protein', 'carb',\n",
    "                 'fibre', 'alcohol', 'energy_fat', 'energy_saturate', 'energy_sugar', 'energy_protein',\n",
    "                 'energy_carb', 'energy_fibre', 'energy_alcohol', 'energy_tot', 'f_energy_fat', 'f_energy_saturate', \n",
    "                 'f_energy_sugar', 'f_energy_protein', 'f_energy_carb', 'f_energy_fibre', 'f_energy_alcohol', \n",
    "                 'energy_density', 'h_nutrients_weight', 'h_nutrients_weight_norm', 'h_nutrients_calories',\n",
    "                  'h_nutrients_calories_norm', 'representativeness_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before merging set index of df_atlas to the ward code\n",
    "df_atlas.set_index('New Code', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>volume</th>\n",
       "      <th>fat</th>\n",
       "      <th>saturate</th>\n",
       "      <th>salt</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>carb</th>\n",
       "      <th>fibre</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>...</th>\n",
       "      <th>Level 2 qualifications</th>\n",
       "      <th>Apprenticeship qualifications</th>\n",
       "      <th>Level 3 qualifications</th>\n",
       "      <th>Level &gt;=4 qualifications</th>\n",
       "      <th>Other qualifications</th>\n",
       "      <th>% of 16+ who are schoolchildren and full-time students: Age 18 and over</th>\n",
       "      <th>Bad Health</th>\n",
       "      <th>Limited activities</th>\n",
       "      <th>Well-Being</th>\n",
       "      <th>IOD AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E05000026</th>\n",
       "      <td>449.535137</td>\n",
       "      <td>125.960833</td>\n",
       "      <td>9.488797</td>\n",
       "      <td>3.693721</td>\n",
       "      <td>0.583240</td>\n",
       "      <td>10.966213</td>\n",
       "      <td>4.977560</td>\n",
       "      <td>19.381951</td>\n",
       "      <td>1.564721</td>\n",
       "      <td>0.198172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.167</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-0.492858</td>\n",
       "      <td>-1.121216</td>\n",
       "      <td>7.897959</td>\n",
       "      <td>0.694138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000027</th>\n",
       "      <td>413.130263</td>\n",
       "      <td>110.664114</td>\n",
       "      <td>9.733634</td>\n",
       "      <td>3.565913</td>\n",
       "      <td>0.568184</td>\n",
       "      <td>10.514427</td>\n",
       "      <td>5.211694</td>\n",
       "      <td>18.950348</td>\n",
       "      <td>1.581960</td>\n",
       "      <td>0.209917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.089</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.409580</td>\n",
       "      <td>1.429760</td>\n",
       "      <td>7.358842</td>\n",
       "      <td>0.992115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000028</th>\n",
       "      <td>407.100472</td>\n",
       "      <td>121.990710</td>\n",
       "      <td>9.216310</td>\n",
       "      <td>3.613582</td>\n",
       "      <td>0.610536</td>\n",
       "      <td>10.690272</td>\n",
       "      <td>5.192412</td>\n",
       "      <td>19.662048</td>\n",
       "      <td>1.572323</td>\n",
       "      <td>0.225425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.100</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.647385</td>\n",
       "      <td>1.429760</td>\n",
       "      <td>7.609123</td>\n",
       "      <td>0.601395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000029</th>\n",
       "      <td>384.173858</td>\n",
       "      <td>122.245578</td>\n",
       "      <td>9.700137</td>\n",
       "      <td>3.961264</td>\n",
       "      <td>0.533180</td>\n",
       "      <td>12.938606</td>\n",
       "      <td>4.718184</td>\n",
       "      <td>20.084734</td>\n",
       "      <td>1.550344</td>\n",
       "      <td>0.200380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.083</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.488848</td>\n",
       "      <td>2.119213</td>\n",
       "      <td>7.108108</td>\n",
       "      <td>1.168602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000030</th>\n",
       "      <td>356.882607</td>\n",
       "      <td>109.959688</td>\n",
       "      <td>9.381808</td>\n",
       "      <td>3.614663</td>\n",
       "      <td>0.566784</td>\n",
       "      <td>11.332898</td>\n",
       "      <td>5.307003</td>\n",
       "      <td>19.581403</td>\n",
       "      <td>1.607947</td>\n",
       "      <td>0.168952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.061</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.775434</td>\n",
       "      <td>1.291869</td>\n",
       "      <td>7.887917</td>\n",
       "      <td>0.065051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000645</th>\n",
       "      <td>387.651694</td>\n",
       "      <td>100.374890</td>\n",
       "      <td>9.011954</td>\n",
       "      <td>3.558849</td>\n",
       "      <td>0.584727</td>\n",
       "      <td>9.403091</td>\n",
       "      <td>5.499603</td>\n",
       "      <td>16.729870</td>\n",
       "      <td>1.609476</td>\n",
       "      <td>0.292334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.099</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>0.257690</td>\n",
       "      <td>7.653520</td>\n",
       "      <td>-0.504062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000646</th>\n",
       "      <td>391.296517</td>\n",
       "      <td>102.209867</td>\n",
       "      <td>8.810350</td>\n",
       "      <td>3.379945</td>\n",
       "      <td>0.604999</td>\n",
       "      <td>9.350598</td>\n",
       "      <td>5.584789</td>\n",
       "      <td>17.240961</td>\n",
       "      <td>1.640990</td>\n",
       "      <td>0.209072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.104</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.537629</td>\n",
       "      <td>0.188745</td>\n",
       "      <td>7.578400</td>\n",
       "      <td>-0.262902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000647</th>\n",
       "      <td>391.146713</td>\n",
       "      <td>115.080184</td>\n",
       "      <td>8.642757</td>\n",
       "      <td>3.398100</td>\n",
       "      <td>0.584833</td>\n",
       "      <td>9.446028</td>\n",
       "      <td>5.321004</td>\n",
       "      <td>17.579308</td>\n",
       "      <td>1.680360</td>\n",
       "      <td>0.299310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.097</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.500708</td>\n",
       "      <td>8.185989</td>\n",
       "      <td>-0.452034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000648</th>\n",
       "      <td>400.832576</td>\n",
       "      <td>109.727023</td>\n",
       "      <td>8.919674</td>\n",
       "      <td>3.512147</td>\n",
       "      <td>0.549463</td>\n",
       "      <td>9.623928</td>\n",
       "      <td>5.259262</td>\n",
       "      <td>17.940815</td>\n",
       "      <td>1.611090</td>\n",
       "      <td>0.195706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.131</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.994945</td>\n",
       "      <td>2.739721</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.459673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E05000649</th>\n",
       "      <td>370.849508</td>\n",
       "      <td>99.419205</td>\n",
       "      <td>9.154919</td>\n",
       "      <td>3.642411</td>\n",
       "      <td>0.560853</td>\n",
       "      <td>10.170574</td>\n",
       "      <td>5.328714</td>\n",
       "      <td>17.765000</td>\n",
       "      <td>1.665483</td>\n",
       "      <td>0.217665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.134</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-0.334322</td>\n",
       "      <td>-0.983325</td>\n",
       "      <td>7.731481</td>\n",
       "      <td>-0.390090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               weight      volume       fat  saturate      salt      sugar  \\\n",
       "E05000026  449.535137  125.960833  9.488797  3.693721  0.583240  10.966213   \n",
       "E05000027  413.130263  110.664114  9.733634  3.565913  0.568184  10.514427   \n",
       "E05000028  407.100472  121.990710  9.216310  3.613582  0.610536  10.690272   \n",
       "E05000029  384.173858  122.245578  9.700137  3.961264  0.533180  12.938606   \n",
       "E05000030  356.882607  109.959688  9.381808  3.614663  0.566784  11.332898   \n",
       "...               ...         ...       ...       ...       ...        ...   \n",
       "E05000645  387.651694  100.374890  9.011954  3.558849  0.584727   9.403091   \n",
       "E05000646  391.296517  102.209867  8.810350  3.379945  0.604999   9.350598   \n",
       "E05000647  391.146713  115.080184  8.642757  3.398100  0.584833   9.446028   \n",
       "E05000648  400.832576  109.727023  8.919674  3.512147  0.549463   9.623928   \n",
       "E05000649  370.849508   99.419205  9.154919  3.642411  0.560853  10.170574   \n",
       "\n",
       "            protein       carb     fibre   alcohol  ...  \\\n",
       "E05000026  4.977560  19.381951  1.564721  0.198172  ...   \n",
       "E05000027  5.211694  18.950348  1.581960  0.209917  ...   \n",
       "E05000028  5.192412  19.662048  1.572323  0.225425  ...   \n",
       "E05000029  4.718184  20.084734  1.550344  0.200380  ...   \n",
       "E05000030  5.307003  19.581403  1.607947  0.168952  ...   \n",
       "...             ...        ...       ...       ...  ...   \n",
       "E05000645  5.499603  16.729870  1.609476  0.292334  ...   \n",
       "E05000646  5.584789  17.240961  1.640990  0.209072  ...   \n",
       "E05000647  5.321004  17.579308  1.680360  0.299310  ...   \n",
       "E05000648  5.259262  17.940815  1.611090  0.195706  ...   \n",
       "E05000649  5.328714  17.765000  1.665483  0.217665  ...   \n",
       "\n",
       "           Level 2 qualifications  Apprenticeship qualifications  \\\n",
       "E05000026                   0.115                          0.011   \n",
       "E05000027                   0.157                          0.018   \n",
       "E05000028                   0.153                          0.020   \n",
       "E05000029                   0.149                          0.022   \n",
       "E05000030                   0.165                          0.028   \n",
       "...                           ...                            ...   \n",
       "E05000645                   0.076                          0.009   \n",
       "E05000646                   0.081                          0.009   \n",
       "E05000647                   0.071                          0.010   \n",
       "E05000648                   0.096                          0.008   \n",
       "E05000649                   0.068                          0.006   \n",
       "\n",
       "           Level 3 qualifications  Level >=4 qualifications  \\\n",
       "E05000026                   0.085                     0.345   \n",
       "E05000027                   0.093                     0.167   \n",
       "E05000028                   0.091                     0.206   \n",
       "E05000029                   0.100                     0.195   \n",
       "E05000030                   0.100                     0.185   \n",
       "...                           ...                       ...   \n",
       "E05000645                   0.080                     0.551   \n",
       "E05000646                   0.088                     0.531   \n",
       "E05000647                   0.085                     0.585   \n",
       "E05000648                   0.089                     0.357   \n",
       "E05000649                   0.095                     0.546   \n",
       "\n",
       "           Other qualifications  \\\n",
       "E05000026                 0.167   \n",
       "E05000027                 0.089   \n",
       "E05000028                 0.100   \n",
       "E05000029                 0.083   \n",
       "E05000030                 0.061   \n",
       "...                         ...   \n",
       "E05000645                 0.099   \n",
       "E05000646                 0.104   \n",
       "E05000647                 0.097   \n",
       "E05000648                 0.131   \n",
       "E05000649                 0.134   \n",
       "\n",
       "           % of 16+ who are schoolchildren and full-time students: Age 18 and over  \\\n",
       "E05000026                                               14.3                         \n",
       "E05000027                                                5.8                         \n",
       "E05000028                                                7.7                         \n",
       "E05000029                                                5.3                         \n",
       "E05000030                                                5.0                         \n",
       "...                                                      ...                         \n",
       "E05000645                                                6.4                         \n",
       "E05000646                                                7.7                         \n",
       "E05000647                                                7.7                         \n",
       "E05000648                                                7.4                         \n",
       "E05000649                                               10.1                         \n",
       "\n",
       "           Bad Health  Limited activities  Well-Being   IOD AVG  \n",
       "E05000026   -0.492858           -1.121216    7.897959  0.694138  \n",
       "E05000027    1.409580            1.429760    7.358842  0.992115  \n",
       "E05000028    1.647385            1.429760    7.609123  0.601395  \n",
       "E05000029    1.488848            2.119213    7.108108  1.168602  \n",
       "E05000030    0.775434            1.291869    7.887917  0.065051  \n",
       "...               ...                 ...         ...       ...  \n",
       "E05000645    0.616897            0.257690    7.653520 -0.504062  \n",
       "E05000646    0.537629            0.188745    7.578400 -0.262902  \n",
       "E05000647    0.220556           -0.500708    8.185989 -0.452034  \n",
       "E05000648    2.994945            2.739721    8.000000  1.459673  \n",
       "E05000649   -0.334322           -0.983325    7.731481 -0.390090  \n",
       "\n",
       "[483 rows x 66 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the data sets by ward\n",
    "df_ward_atlas = pd.merge(df_ward[important_cols], df_atlas, how='inner', left_index=True, right_index=True, validate='1:1')\n",
    "df_ward_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level 1 qualifications           0.824816\n",
       "Level >=4 qualifications        -0.787306\n",
       "Level 2 qualifications           0.772630\n",
       "No qualifications                0.686948\n",
       "Apprenticeship qualifications    0.643280\n",
       "Household Income Median         -0.622505\n",
       "Aged 16-64                      -0.575291\n",
       "Aged 0-15                        0.499667\n",
       "Religion not stated             -0.476486\n",
       "Mixed                           -0.413051\n",
       "Limited activities               0.382785\n",
       "No religion                     -0.374852\n",
       "Buddhist                        -0.343616\n",
       "Other                           -0.307474\n",
       "Jewish                          -0.305896\n",
       "Not Born in UK                  -0.300743\n",
       "Born in UK                       0.300743\n",
       "Aged 65+                         0.260227\n",
       "Asian or Asian British           0.249848\n",
       "Hindu                            0.233352\n",
       "Sikh                             0.232523\n",
       "Christian                        0.206357\n",
       "Bad Health                       0.202186\n",
       "White                           -0.160661\n",
       "Level 3 qualifications           0.157957\n",
       "Muslim                           0.134663\n",
       "Black or Black British           0.075192\n",
       "IOD AVG                          0.054705\n",
       "Other religions                 -0.046007\n",
       "Other qualifications            -0.031801\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carb_energy_corr = df_ward_atlas[all_features].corrwith(df_ward_atlas['energy_carb'], method='pearson')\n",
    "carb_energy_corr = carb_energy_corr.sort_values(ascending=False, key=np.abs)\n",
    "carb_energy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of linearly dependent cols\n",
    "for cols in [age_cols, ethnicities_cols, religion_cols, born_cols, qualilication_cols]:\n",
    "    carb_energy_corr.drop(carb_energy_corr[cols].index[-1], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level 1 qualifications           0.824816\n",
       "Level >=4 qualifications        -0.787306\n",
       "Level 2 qualifications           0.772630\n",
       "No qualifications                0.686948\n",
       "Apprenticeship qualifications    0.643280\n",
       "Household Income Median         -0.622505\n",
       "Aged 16-64                      -0.575291\n",
       "Aged 0-15                        0.499667\n",
       "Mixed                           -0.413051\n",
       "Limited activities               0.382785\n",
       "No religion                     -0.374852\n",
       "Buddhist                        -0.343616\n",
       "Jewish                          -0.305896\n",
       "Born in UK                       0.300743\n",
       "Asian or Asian British           0.249848\n",
       "Hindu                            0.233352\n",
       "Sikh                             0.232523\n",
       "Christian                        0.206357\n",
       "Bad Health                       0.202186\n",
       "White                           -0.160661\n",
       "Level 3 qualifications           0.157957\n",
       "Muslim                           0.134663\n",
       "Black or Black British           0.075192\n",
       "IOD AVG                          0.054705\n",
       "Other religions                 -0.046007\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carb_energy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(df_corrs, target_col, verbose=False):\n",
    "\n",
    "    num_features = 1\n",
    "    repeat = 100\n",
    "    best_score = 0\n",
    "    best_num_features = 0\n",
    "    delay = 10\n",
    "    not_improvements = 0\n",
    "\n",
    "    while (not_improvements < delay) and (num_features < len(df_corrs)):\n",
    "        features = list(df_corrs[:num_features].keys())\n",
    "        x_data = df_ward_atlas[features]\n",
    "        y_data = df_ward_atlas[target_col]\n",
    "        res_train = []\n",
    "        res_test = []\n",
    "        for i in range(repeat):\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 1/3)\n",
    "            model = LinearRegression()\n",
    "            model.fit(x_train, y_train)\n",
    "            res_train.append(model.score(x_train, y_train))\n",
    "            res_test.append(model.score(x_test, y_test))\n",
    "        res_train = np.array(res_train)\n",
    "        res_test = np.array(res_test)\n",
    "        res_train = np.mean(res_train)\n",
    "        res_test = np.mean(res_test)\n",
    "        if (res_test > best_score):\n",
    "            summary_str = 'R2 score on test data improved by {:.5}'.format(res_test-best_score)\n",
    "            best_score = res_test\n",
    "            best_num_features = num_features\n",
    "            not_improvements = 0\n",
    "        else:\n",
    "            summary_str = 'R2 score on test data did not improved'\n",
    "            not_improvements += 1\n",
    "        if verbose:\n",
    "            print('Added feature {}: {}'.format(num_features, df_corrs.keys()[num_features-1]))\n",
    "            print('Average r2_score on train data: {:.5}, on test data {:.5}'.format(res_train, res_test))\n",
    "            print(summary_str + '\\n')\n",
    "        num_features += 1\n",
    "    \n",
    "    return best_score, best_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection_brute_force(df_corrs_, target_col, verbose=False):\n",
    "    num_features = 1\n",
    "    repeat = 100\n",
    "    global_test_best = 0\n",
    "    selected_cols_best = None\n",
    "    delay = 3\n",
    "    not_improvements = 0\n",
    "\n",
    "    df_corrs = df_corrs_.copy()\n",
    "    selected_cols = []\n",
    "\n",
    "    while (not_improvements < delay) and (len(df_corrs) > 0):\n",
    "        res_train = {}\n",
    "        res_test = {}\n",
    "        local_train_best = 0\n",
    "        local_test_best = 0\n",
    "        best_new_col = None\n",
    "        for new_col in df_corrs.index:\n",
    "            trial_cols = selected_cols + [new_col]       \n",
    "            x_data = df_ward_atlas[trial_cols]\n",
    "            y_data = df_ward_atlas[target_col]\n",
    "            res_train[new_col] = []\n",
    "            res_test[new_col] = []\n",
    "            for i in range(repeat):\n",
    "                x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 1/3)\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_train, y_train)\n",
    "                res_train[new_col].append(model.score(x_train, y_train))\n",
    "                res_test[new_col].append(model.score(x_test, y_test))\n",
    "            res_train[new_col] = np.array(res_train[new_col])\n",
    "            res_test[new_col] = np.array(res_test[new_col])\n",
    "            res_train[new_col] = np.mean(res_train[new_col])\n",
    "            res_test[new_col] = np.mean(res_test[new_col])\n",
    "            if (res_test[new_col] > local_test_best):\n",
    "                local_test_best = res_test[new_col]\n",
    "                local_train_best = res_train[new_col]\n",
    "                best_new_col = new_col\n",
    "        \n",
    "        selected_cols.append(best_new_col)\n",
    "        df_corrs.drop(best_new_col, axis=0, inplace=True)\n",
    "        if (local_test_best > global_test_best):\n",
    "            summary_str = 'R2 score on test data improved by {:.5}'.format(local_test_best-global_test_best)\n",
    "            global_test_best = local_test_best\n",
    "            selected_cols_best = selected_cols.copy()\n",
    "            not_improvements = 0\n",
    "        else:\n",
    "            summary_str = 'R2 score on test data did not improved'\n",
    "            not_improvements += 1\n",
    "        if verbose:\n",
    "            print('Added feature {}: {}'.format(num_features, best_new_col))\n",
    "            print('Average r2_score on train data: {:.5}, on test data {:.5}'.format(local_train_best, local_test_best))\n",
    "            print(summary_str + '\\n')\n",
    "        num_features += 1\n",
    "        \n",
    "    return global_test_best, selected_cols_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added feature 1: Level 1 qualifications\n",
      "Average r2_score on train data: 0.68185, on test data 0.6715\n",
      "R2 score on test data improved by 0.6715\n",
      "\n",
      "Added feature 2: Mixed\n",
      "Average r2_score on train data: 0.71433, on test data 0.70443\n",
      "R2 score on test data improved by 0.032934\n",
      "\n",
      "Added feature 3: Jewish\n",
      "Average r2_score on train data: 0.73438, on test data 0.72843\n",
      "R2 score on test data improved by 0.023998\n",
      "\n",
      "Added feature 4: Asian or Asian British\n",
      "Average r2_score on train data: 0.75126, on test data 0.74344\n",
      "R2 score on test data improved by 0.015014\n",
      "\n",
      "Added feature 5: Level 2 qualifications\n",
      "Average r2_score on train data: 0.76619, on test data 0.74868\n",
      "R2 score on test data improved by 0.0052364\n",
      "\n",
      "Added feature 6: Muslim\n",
      "Average r2_score on train data: 0.76563, on test data 0.75919\n",
      "R2 score on test data improved by 0.010511\n",
      "\n",
      "Added feature 7: No religion\n",
      "Average r2_score on train data: 0.77378, on test data 0.76783\n",
      "R2 score on test data improved by 0.0086428\n",
      "\n",
      "Added feature 8: Level >=4 qualifications\n",
      "Average r2_score on train data: 0.77367, on test data 0.77084\n",
      "R2 score on test data improved by 0.0030089\n",
      "\n",
      "Added feature 9: Aged 16-64\n",
      "Average r2_score on train data: 0.77702, on test data 0.76771\n",
      "R2 score on test data did not improved\n",
      "\n",
      "Added feature 10: Apprenticeship qualifications\n",
      "Average r2_score on train data: 0.77656, on test data 0.76812\n",
      "R2 score on test data did not improved\n",
      "\n",
      "Added feature 11: Aged 0-15\n",
      "Average r2_score on train data: 0.77802, on test data 0.7667\n",
      "R2 score on test data did not improved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_test_best, selected_cols_best  = forward_feature_selection_brute_force(carb_energy_corr, 'energy_carb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_test_best, selected_cols_best  = forward_feature_selection_brute_force(carb_energy_corr, 'energy_carb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708398809492684\n",
      "['Level 1 qualifications', 'Mixed', 'Jewish', 'Asian or Asian British', 'Level 2 qualifications', 'Muslim', 'No religion', 'Level >=4 qualifications']\n"
     ]
    }
   ],
   "source": [
    "print(global_test_best)\n",
    "print(selected_cols_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_fat: best r2 score = 0.34637, num features = 10\n",
      "energy_saturate: best r2 score = 0.34950, num features = 11\n",
      "energy_sugar: best r2 score = 0.59490, num features = 13\n",
      "energy_protein: best r2 score = 0.61036, num features = 15\n",
      "energy_carb: best r2 score = 0.76988, num features = 9\n",
      "energy_fibre: best r2 score = 0.58866, num features = 10\n",
      "energy_alcohol: best r2 score = 0.39419, num features = 8\n",
      "energy_tot: best r2 score = 0.65720, num features = 9\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['energy_fat', 'energy_saturate', 'energy_sugar', 'energy_protein',\n",
    "                 'energy_carb', 'energy_fibre', 'energy_alcohol', 'energy_tot']\n",
    "global_test_best = {}\n",
    "selected_cols_best = {}\n",
    "energy_corr = {}\n",
    "for y in target_cols:\n",
    "    energy_corr[y] = df_ward_atlas[all_features].corrwith(df_ward_atlas[y], method='pearson')\n",
    "    energy_corr[y] = energy_corr[y].sort_values(ascending=False, key=np.abs)\n",
    "    #get rid of linearly dependent cols\n",
    "    for cols in [age_cols, ethnicities_cols, religion_cols, born_cols, qualilication_cols]:\n",
    "        energy_corr[y].drop(energy_corr[y][cols].index[-1], axis=0, inplace=True)\n",
    "    global_test_best[y], selected_cols_best[y]  = forward_feature_selection_brute_force(energy_corr[y], y)\n",
    "    print('{}: best r2 score = {:.5f}, num features = {}'.format(y, global_test_best[y], len(selected_cols_best[y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for 'energy_fat' prediction: ['Level 1 qualifications', 'Jewish', 'Mixed', 'Aged 0-15', 'Christian', 'Black or Black British', 'Muslim', 'No religion', 'Asian or Asian British', 'IOD AVG']\n",
      "features for 'energy_saturate' prediction: ['Asian or Asian British', 'Born in UK', 'Muslim', 'White', 'Jewish', 'Aged 0-15', 'Mixed', 'Apprenticeship qualifications', 'Level 1 qualifications', 'Level 3 qualifications', 'Other religions']\n",
      "features for 'energy_sugar' prediction: ['Level 1 qualifications', 'Black or Black British', 'Bad Health', 'White', 'Hindu', 'Mixed', 'Asian or Asian British', 'No religion', 'Aged 0-15', 'Christian', 'Muslim', 'IOD AVG', 'Apprenticeship qualifications']\n",
      "features for 'energy_protein' prediction: ['Asian or Asian British', 'Jewish', 'Level 1 qualifications', 'Sikh', 'Muslim', 'No religion', 'Level 2 qualifications', 'Christian', 'IOD AVG', 'Household Income Median', 'Apprenticeship qualifications', 'Buddhist', 'Level >=4 qualifications', 'Born in UK', 'Aged 16-64']\n",
      "features for 'energy_carb' prediction: ['Level 1 qualifications', 'Mixed', 'Jewish', 'White', 'Born in UK', 'Other religions', 'Limited activities', 'Level >=4 qualifications', 'No qualifications']\n",
      "features for 'energy_fibre' prediction: ['IOD AVG', 'No religion', 'Level 1 qualifications', 'Sikh', 'White', 'Aged 16-64', 'Household Income Median', 'Jewish', 'No qualifications', 'Black or Black British']\n",
      "features for 'energy_alcohol' prediction: ['Level >=4 qualifications', 'No religion', 'Jewish', 'Muslim', 'Apprenticeship qualifications', 'Other religions', 'IOD AVG', 'Bad Health']\n",
      "features for 'energy_tot' prediction: ['Level 1 qualifications', 'Jewish', 'Mixed', 'Aged 0-15', 'Limited activities', 'Christian', 'Born in UK', 'Muslim', 'Sikh']\n"
     ]
    }
   ],
   "source": [
    "for y in target_cols:\n",
    "    print(f'features for \\'{y}\\' prediction:', selected_cols_best[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_formula(cols):\n",
    "    cols = list(map(lambda s: 'Q(\"{}\")'.format(s), cols))\n",
    "    return ' + '.join(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             energy_fat   R-squared:                       0.369\n",
      "Model:                            OLS   Adj. R-squared:                  0.356\n",
      "Method:                 Least Squares   F-statistic:                     27.63\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           1.50e-41\n",
      "Time:                        01:33:49   Log-Likelihood:                -1160.8\n",
      "No. Observations:                 483   AIC:                             2344.\n",
      "Df Residuals:                     472   BIC:                             2390.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      67.4103      3.553     18.975      0.000      60.430      74.391\n",
      "Q(\"Level 1 qualifications\")    24.0243      5.969      4.025      0.000      12.294      35.754\n",
      "Q(\"Jewish\")                   -15.9587      5.044     -3.164      0.002     -25.869      -6.048\n",
      "Q(\"Mixed\")                    -14.0683     16.378     -0.859      0.391     -46.251      18.114\n",
      "Q(\"Aged 0-15\")                 20.9680      5.106      4.107      0.000      10.935      31.001\n",
      "Q(\"Christian\")                  6.5188      3.755      1.736      0.083      -0.860      13.897\n",
      "Q(\"Black or Black British\")   -12.3686      3.277     -3.775      0.000     -18.807      -5.930\n",
      "Q(\"Muslim\")                    12.5124      3.349      3.736      0.000       5.932      19.093\n",
      "Q(\"No religion\")               17.0790      4.681      3.648      0.000       7.880      26.278\n",
      "Q(\"Asian or Asian British\")     8.4919      3.127      2.716      0.007       2.348      14.636\n",
      "Q(\"IOD AVG\")                    0.1025      0.298      0.344      0.731      -0.483       0.688\n",
      "==============================================================================\n",
      "Omnibus:                      319.961   Durbin-Watson:                   1.684\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8305.069\n",
      "Skew:                           2.431   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.724   Cond. No.                         162.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_fat'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically significant features (with p-value < 0.05): Black or Black British, Asian or Asian British (etnicities), Jewish, Muslim, No religion (religions), Level 1 qualifications, Aged 0-15. More precisely, we see that amount of consumed energy from fats depends on:\n",
    "1) Etnicity: less for Black or Black British, more for Asian or Asian British. <br>\n",
    "2) Religion: less for Jewish, more for Muslim and people with no religion. <br>\n",
    "3) Qualification: more for people with the lowest qualification. <br>\n",
    "4) Age: more for children (age 0-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_saturate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        energy_saturate   R-squared:                       0.379\n",
      "Model:                            OLS   Adj. R-squared:                  0.364\n",
      "Method:                 Least Squares   F-statistic:                     26.13\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           2.36e-42\n",
      "Time:                        01:43:30   Log-Likelihood:                -785.08\n",
      "No. Observations:                 483   AIC:                             1594.\n",
      "Df Residuals:                     471   BIC:                             1644.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             19.3212      1.586     12.183      0.000      16.205      22.438\n",
      "Q(\"Asian or Asian British\")           11.4181      1.327      8.604      0.000       8.811      14.026\n",
      "Q(\"Born in UK\")                       -1.3437      1.309     -1.027      0.305      -3.916       1.228\n",
      "Q(\"Muslim\")                            8.5449      1.264      6.760      0.000       6.061      11.029\n",
      "Q(\"White\")                            11.7840      1.532      7.690      0.000       8.773      14.795\n",
      "Q(\"Jewish\")                           -9.4583      1.442     -6.561      0.000     -12.291      -6.625\n",
      "Q(\"Aged 0-15\")                         6.8194      2.562      2.661      0.008       1.784      11.855\n",
      "Q(\"Mixed\")                            29.5564      8.063      3.666      0.000      13.712      45.401\n",
      "Q(\"Apprenticeship qualifications\")    -9.7483     16.780     -0.581      0.562     -42.722      23.225\n",
      "Q(\"Level 1 qualifications\")           12.5405      4.747      2.642      0.009       3.213      21.868\n",
      "Q(\"Level 3 qualifications\")           -6.7662      2.983     -2.269      0.024     -12.627      -0.905\n",
      "Q(\"Other religions\")                  23.5763     11.010      2.141      0.033       1.942      45.211\n",
      "==============================================================================\n",
      "Omnibus:                      349.324   Durbin-Watson:                   1.844\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11454.779\n",
      "Skew:                           2.686   Prob(JB):                         0.00\n",
      "Kurtosis:                      26.245   Cond. No.                         420.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_saturate'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_sugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           energy_sugar   R-squared:                       0.602\n",
      "Model:                            OLS   Adj. R-squared:                  0.591\n",
      "Method:                 Least Squares   F-statistic:                     54.56\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           3.82e-85\n",
      "Time:                        01:45:33   Log-Likelihood:                -1112.2\n",
      "No. Observations:                 483   AIC:                             2252.\n",
      "Df Residuals:                     469   BIC:                             2311.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             19.5480      6.797      2.876      0.004       6.191      32.905\n",
      "Q(\"Level 1 qualifications\")           84.8109     10.708      7.921      0.000      63.770     105.852\n",
      "Q(\"Black or Black British\")           -0.4996      7.499     -0.067      0.947     -15.236      14.237\n",
      "Q(\"Bad Health\")                        0.3381      0.236      1.434      0.152      -0.125       0.801\n",
      "Q(\"White\")                             5.4827      7.438      0.737      0.461      -9.134      20.099\n",
      "Q(\"Hindu\")                            -5.5022      3.875     -1.420      0.156     -13.117       2.112\n",
      "Q(\"Mixed\")                           -15.2619     18.441     -0.828      0.408     -51.500      20.976\n",
      "Q(\"Asian or Asian British\")           17.8987      6.871      2.605      0.009       4.397      31.400\n",
      "Q(\"No religion\")                      13.5548      3.947      3.435      0.001       5.800      21.310\n",
      "Q(\"Aged 0-15\")                         3.6617      5.021      0.729      0.466      -6.205      13.528\n",
      "Q(\"Christian\")                         7.9276      2.454      3.231      0.001       3.106      12.749\n",
      "Q(\"Muslim\")                            5.3225      3.693      1.441      0.150      -1.935      12.580\n",
      "Q(\"IOD AVG\")                          -1.0930      0.351     -3.114      0.002      -1.783      -0.403\n",
      "Q(\"Apprenticeship qualifications\")   -68.5670     37.584     -1.824      0.069    -142.422       5.288\n",
      "==============================================================================\n",
      "Omnibus:                      396.803   Durbin-Watson:                   1.689\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20469.464\n",
      "Skew:                           3.100   Prob(JB):                         0.00\n",
      "Kurtosis:                      34.284   Cond. No.                         480.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_sugar'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         energy_protein   R-squared:                       0.639\n",
      "Model:                            OLS   Adj. R-squared:                  0.628\n",
      "Method:                 Least Squares   F-statistic:                     55.17\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           3.27e-93\n",
      "Time:                        01:47:22   Log-Likelihood:                -384.19\n",
      "No. Observations:                 483   AIC:                             800.4\n",
      "Df Residuals:                     467   BIC:                             867.3\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                             21.8057      1.239     17.595      0.000      19.370      24.241\n",
      "Q(\"Asian or Asian British\")           -7.4556      0.655    -11.374      0.000      -8.744      -6.168\n",
      "Q(\"Jewish\")                           -9.4217      1.059     -8.899      0.000     -11.502      -7.341\n",
      "Q(\"Level 1 qualifications\")          -11.1822      3.584     -3.120      0.002     -18.225      -4.140\n",
      "Q(\"Sikh\")                              4.3579      0.816      5.339      0.000       2.754       5.962\n",
      "Q(\"Muslim\")                            0.7174      0.692      1.037      0.300      -0.642       2.077\n",
      "Q(\"No religion\")                      -6.4904      1.274     -5.096      0.000      -8.993      -3.988\n",
      "Q(\"Level 2 qualifications\")            0.7922      3.438      0.230      0.818      -5.964       7.548\n",
      "Q(\"Christian\")                        -2.3165      0.781     -2.966      0.003      -3.851      -0.782\n",
      "Q(\"IOD AVG\")                          -0.1146      0.067     -1.710      0.088      -0.246       0.017\n",
      "Q(\"Household Income Median\")          -0.2228      0.071     -3.131      0.002      -0.363      -0.083\n",
      "Q(\"Apprenticeship qualifications\")     6.2486      8.171      0.765      0.445      -9.807      22.305\n",
      "Q(\"Buddhist\")                         22.4165      6.419      3.492      0.001       9.803      35.030\n",
      "Q(\"Level >=4 qualifications\")          0.8106      0.941      0.861      0.390      -1.039       2.661\n",
      "Q(\"Born in UK\")                        2.4869      0.747      3.330      0.001       1.019       3.955\n",
      "Q(\"Aged 16-64\")                        2.8856      1.084      2.662      0.008       0.755       5.016\n",
      "==============================================================================\n",
      "Omnibus:                        9.666   Durbin-Watson:                   1.619\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):               12.338\n",
      "Skew:                          -0.204   Prob(JB):                      0.00209\n",
      "Kurtosis:                       3.668   Cond. No.                         520.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_protein'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_carb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            energy_carb   R-squared:                       0.775\n",
      "Model:                            OLS   Adj. R-squared:                  0.771\n",
      "Method:                 Least Squares   F-statistic:                     181.4\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):          3.14e-147\n",
      "Time:                        01:44:00   Log-Likelihood:                -1151.7\n",
      "No. Observations:                 483   AIC:                             2323.\n",
      "Df Residuals:                     473   BIC:                             2365.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                        75.0937      3.271     22.957      0.000      68.666      81.521\n",
      "Q(\"Level 1 qualifications\")      30.7539     16.339      1.882      0.060      -1.352      62.860\n",
      "Q(\"Mixed\")                      -89.8382      9.485     -9.472      0.000    -108.476     -71.200\n",
      "Q(\"Jewish\")                     -15.4931      2.960     -5.234      0.000     -21.310      -9.676\n",
      "Q(\"White\")                      -14.5215      1.826     -7.953      0.000     -18.110     -10.933\n",
      "Q(\"Born in UK\")                  19.6703      2.786      7.061      0.000      14.197      25.144\n",
      "Q(\"Other religions\")             -8.7660     21.287     -0.412      0.681     -50.595      33.063\n",
      "Q(\"Limited activities\")          -0.4544      0.222     -2.047      0.041      -0.891      -0.018\n",
      "Q(\"Level >=4 qualifications\")   -13.3712      4.657     -2.871      0.004     -22.523      -4.220\n",
      "Q(\"No qualifications\")            4.2454      7.360      0.577      0.564     -10.216      18.707\n",
      "==============================================================================\n",
      "Omnibus:                       27.240   Durbin-Watson:                   1.588\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.883\n",
      "Skew:                           0.422   Prob(JB):                     8.04e-10\n",
      "Kurtosis:                       4.170   Cond. No.                         252.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_carb'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically significant features (with p-value < 0.05): White, Mixed (etnicities), Jewish (religion), Born in UK, Limited activities, Level >=4 qualifications (i. e. maximum level of qualification). More precisely, we see that amount of energy consumed from carbohidrates depends on:\n",
    "1) Etnicity: less for white and (especially) mixed people than in average\n",
    "2) Religion: less for Jewish people\n",
    "3) Place of birth: more for people born in UK than for those who were born abroad\n",
    "4) Health state: less for people whose Day-to-day activities are limited a lot\n",
    "5) Qualification: less for highly qualified people, more for low qualified. Here results for 'No qualifications' may be skewed, because this category probably includes all children independently of their mental abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_fibre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           energy_fibre   R-squared:                       0.605\n",
      "Model:                            OLS   Adj. R-squared:                  0.596\n",
      "Method:                 Least Squares   F-statistic:                     72.19\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           1.40e-88\n",
      "Time:                        01:48:23   Log-Likelihood:                 485.00\n",
      "No. Observations:                 483   AIC:                            -948.0\n",
      "Df Residuals:                     472   BIC:                            -902.0\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                        3.3963      0.130     26.211      0.000       3.142       3.651\n",
      "Q(\"IOD AVG\")                    -0.0385      0.011     -3.550      0.000      -0.060      -0.017\n",
      "Q(\"No religion\")                 0.0026      0.134      0.019      0.985      -0.260       0.265\n",
      "Q(\"Level 1 qualifications\")     -1.4472      0.347     -4.173      0.000      -2.129      -0.766\n",
      "Q(\"Sikh\")                        0.8129      0.123      6.583      0.000       0.570       1.056\n",
      "Q(\"White\")                       0.3936      0.073      5.417      0.000       0.251       0.536\n",
      "Q(\"Aged 16-64\")                 -0.4994      0.153     -3.255      0.001      -0.801      -0.198\n",
      "Q(\"Household Income Median\")    -0.0422      0.012     -3.630      0.000      -0.065      -0.019\n",
      "Q(\"Jewish\")                     -0.0515      0.105     -0.489      0.625      -0.258       0.155\n",
      "Q(\"No qualifications\")          -0.5426      0.220     -2.462      0.014      -0.976      -0.110\n",
      "Q(\"Black or Black British\")     -0.0833      0.089     -0.937      0.349      -0.258       0.091\n",
      "==============================================================================\n",
      "Omnibus:                       94.543   Durbin-Watson:                   1.863\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              352.100\n",
      "Skew:                           0.843   Prob(JB):                     3.49e-77\n",
      "Kurtosis:                       6.828   Cond. No.                         131.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_fibre'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         energy_alcohol   R-squared:                       0.413\n",
      "Model:                            OLS   Adj. R-squared:                  0.403\n",
      "Method:                 Least Squares   F-statistic:                     41.65\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):           2.60e-50\n",
      "Time:                        01:49:36   Log-Likelihood:                -63.078\n",
      "No. Observations:                 483   AIC:                             144.2\n",
      "Df Residuals:                     474   BIC:                             181.8\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              1.5975      0.155     10.306      0.000       1.293       1.902\n",
      "Q(\"Level >=4 qualifications\")          1.3676      0.262      5.226      0.000       0.853       1.882\n",
      "Q(\"No religion\")                      -0.5177      0.360     -1.440      0.151      -1.224       0.189\n",
      "Q(\"Jewish\")                           -1.2948      0.322     -4.016      0.000      -1.928      -0.661\n",
      "Q(\"Muslim\")                           -1.9564      0.316     -6.196      0.000      -2.577      -1.336\n",
      "Q(\"Apprenticeship qualifications\")    -3.0683      3.260     -0.941      0.347      -9.475       3.338\n",
      "Q(\"Other religions\")                  -6.9563      2.324     -2.993      0.003     -11.524      -2.389\n",
      "Q(\"IOD AVG\")                           0.0541      0.031      1.753      0.080      -0.007       0.115\n",
      "Q(\"Bad Health\")                        0.0003      0.023      0.012      0.991      -0.044       0.045\n",
      "==============================================================================\n",
      "Omnibus:                       38.709   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.739\n",
      "Skew:                           0.598   Prob(JB):                     1.30e-12\n",
      "Kurtosis:                       4.135   Cond. No.                         343.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_alcohol'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model for energy_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             energy_tot   R-squared:                       0.661\n",
      "Model:                            OLS   Adj. R-squared:                  0.655\n",
      "Method:                 Least Squares   F-statistic:                     102.5\n",
      "Date:                Fri, 11 Dec 2020   Prob (F-statistic):          3.32e-105\n",
      "Time:                        01:51:37   Log-Likelihood:                -1405.3\n",
      "No. Observations:                 483   AIC:                             2831.\n",
      "Df Residuals:                     473   BIC:                             2872.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                     164.6510      2.750     59.866      0.000     159.247     170.055\n",
      "Q(\"Level 1 qualifications\")   101.5394     11.116      9.135      0.000      79.697     123.382\n",
      "Q(\"Jewish\")                   -55.5082      5.720     -9.704      0.000     -66.748     -44.268\n",
      "Q(\"Mixed\")                   -113.5997     16.952     -6.701      0.000    -146.911     -80.289\n",
      "Q(\"Aged 0-15\")                 22.0867      8.383      2.635      0.009       5.615      38.559\n",
      "Q(\"Limited activities\")        -0.4854      0.274     -1.770      0.077      -1.024       0.053\n",
      "Q(\"Christian\")                 -7.9466      3.788     -2.098      0.036     -15.390      -0.503\n",
      "Q(\"Born in UK\")                13.9908      3.062      4.568      0.000       7.973      20.009\n",
      "Q(\"Muslim\")                    14.4069      4.614      3.122      0.002       5.340      23.474\n",
      "Q(\"Sikh\")                       4.6586      6.493      0.718      0.473      -8.099      17.417\n",
      "==============================================================================\n",
      "Omnibus:                      205.635   Durbin-Watson:                   1.664\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2606.348\n",
      "Skew:                           1.485   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.986   Cond. No.                         116.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "target = 'energy_tot'\n",
    "model = smf.ols(formula='{} ~ {}'.format(target, to_formula(selected_cols_best[target])),\n",
    "              data=df_ward_atlas)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting a fraction of each nutrient energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_energy_fat: best r2 score = 0.47521, num features = 9\n",
      "f_energy_saturate: best r2 score = 0.43184, num features = 10\n",
      "f_energy_sugar: best r2 score = 0.43231, num features = 8\n",
      "f_energy_protein: best r2 score = 0.70012, num features = 8\n",
      "f_energy_carb: best r2 score = 0.72733, num features = 8\n",
      "f_energy_fibre: best r2 score = 0.76821, num features = 15\n",
      "f_energy_alcohol: best r2 score = 0.45613, num features = 14\n"
     ]
    }
   ],
   "source": [
    "target_cols = ['f_energy_fat', 'f_energy_saturate', \n",
    "                 'f_energy_sugar', 'f_energy_protein', 'f_energy_carb', 'f_energy_fibre', 'f_energy_alcohol']\n",
    "global_test_best = {}\n",
    "selected_cols_best = {}\n",
    "energy_corr = {}\n",
    "for y in target_cols:\n",
    "    energy_corr[y] = df_ward_atlas[all_features].corrwith(df_ward_atlas[y], method='pearson')\n",
    "    energy_corr[y] = energy_corr[y].sort_values(ascending=False, key=np.abs)\n",
    "    #get rid of linearly dependent cols\n",
    "    for cols in [age_cols, ethnicities_cols, religion_cols, born_cols, qualilication_cols]:\n",
    "        energy_corr[y].drop(energy_corr[y][cols].index[-1], axis=0, inplace=True)\n",
    "    global_test_best[y], selected_cols_best[y]  = forward_feature_selection_brute_force(energy_corr[y], y)\n",
    "    print('{}: best r2 score = {:.5f}, num features = {}'.format(y, global_test_best[y], len(selected_cols_best[y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for 'f_energy_fat' prediction: ['Level 2 qualifications', 'Black or Black British', 'Mixed', 'Apprenticeship qualifications', 'Born in UK', 'Aged 0-15', 'Hindu', 'No religion', 'No qualifications']\n",
      "features for 'f_energy_saturate' prediction: ['Level 2 qualifications', 'No religion', 'Black or Black British', 'Mixed', 'Muslim', 'Aged 16-64', 'Other religions', 'Level 1 qualifications', 'No qualifications', 'Level 3 qualifications']\n",
      "features for 'f_energy_sugar' prediction: ['Level 1 qualifications', 'Black or Black British', 'Asian or Asian British', 'IOD AVG', 'No religion', 'Apprenticeship qualifications', 'Jewish', 'Christian']\n",
      "features for 'f_energy_protein' prediction: ['Level >=4 qualifications', 'Asian or Asian British', 'Level 1 qualifications', 'Mixed', 'Aged 0-15', 'Sikh', 'No religion', 'Christian']\n",
      "features for 'f_energy_carb' prediction: ['Level 1 qualifications', 'Hindu', 'Level 2 qualifications', 'White', 'Mixed', 'Born in UK', 'Sikh', 'Black or Black British']\n",
      "features for 'f_energy_fibre' prediction: ['Level >=4 qualifications', 'Jewish', 'White', 'Level 3 qualifications', 'IOD AVG', 'Level 2 qualifications', 'Sikh', 'Asian or Asian British', 'Level 1 qualifications', 'Buddhist', 'Hindu', 'No qualifications', 'Limited activities', 'Household Income Median', 'Aged 16-64']\n",
      "features for 'f_energy_alcohol' prediction: ['Level >=4 qualifications', 'No religion', 'Christian', 'Level 2 qualifications', 'Muslim', 'IOD AVG', 'Level 1 qualifications', 'Jewish', 'Black or Black British', 'White', 'Asian or Asian British', 'Limited activities', 'Mixed', 'Other religions']\n"
     ]
    }
   ],
   "source": [
    "for y in target_cols:\n",
    "    print(f'features for \\'{y}\\' prediction:', selected_cols_best[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for predicting all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import KLDivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['f_energy_fat', 'f_energy_protein', 'f_energy_carb', 'f_energy_fibre', 'f_energy_alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E05000026    1.0\n",
       "E05000027    1.0\n",
       "E05000028    1.0\n",
       "E05000029    1.0\n",
       "E05000030    1.0\n",
       "            ... \n",
       "E05000645    1.0\n",
       "E05000646    1.0\n",
       "E05000647    1.0\n",
       "E05000648    1.0\n",
       "E05000649    1.0\n",
       "Length: 483, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ward_atlas[target_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(np.abs(df_ward_atlas[target_cols].sum(axis=1) - 1 > 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(30,)))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss=KLDivergence(), \n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_ward_atlas[all_features]\n",
    "y_data = df_ward_atlas[target_cols]\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 386 samples, validate on 97 samples\n",
      "Epoch 1/200\n",
      "386/386 [==============================] - 0s 230us/sample - loss: 0.5392 - mean_absolute_error: 0.1801 - val_loss: 0.5628 - val_mean_absolute_error: 0.1853\n",
      "Epoch 2/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.4719 - mean_absolute_error: 0.1665 - val_loss: 0.5016 - val_mean_absolute_error: 0.1731\n",
      "Epoch 3/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.4146 - mean_absolute_error: 0.1536 - val_loss: 0.4478 - val_mean_absolute_error: 0.1613\n",
      "Epoch 4/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.3673 - mean_absolute_error: 0.1423 - val_loss: 0.4020 - val_mean_absolute_error: 0.1505\n",
      "Epoch 5/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.3270 - mean_absolute_error: 0.1319 - val_loss: 0.3599 - val_mean_absolute_error: 0.1398\n",
      "Epoch 6/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.2922 - mean_absolute_error: 0.1223 - val_loss: 0.3244 - val_mean_absolute_error: 0.1302\n",
      "Epoch 7/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.2625 - mean_absolute_error: 0.1137 - val_loss: 0.2944 - val_mean_absolute_error: 0.1216\n",
      "Epoch 8/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.2367 - mean_absolute_error: 0.1059 - val_loss: 0.2694 - val_mean_absolute_error: 0.1143\n",
      "Epoch 9/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.2143 - mean_absolute_error: 0.0989 - val_loss: 0.2472 - val_mean_absolute_error: 0.1074\n",
      "Epoch 10/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.1952 - mean_absolute_error: 0.0926 - val_loss: 0.2278 - val_mean_absolute_error: 0.1012\n",
      "Epoch 11/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1784 - mean_absolute_error: 0.0869 - val_loss: 0.2108 - val_mean_absolute_error: 0.0955\n",
      "Epoch 12/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1636 - mean_absolute_error: 0.0818 - val_loss: 0.1959 - val_mean_absolute_error: 0.0904\n",
      "Epoch 13/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.1508 - mean_absolute_error: 0.0772 - val_loss: 0.1825 - val_mean_absolute_error: 0.0857\n",
      "Epoch 14/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1393 - mean_absolute_error: 0.0730 - val_loss: 0.1708 - val_mean_absolute_error: 0.0815\n",
      "Epoch 15/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1293 - mean_absolute_error: 0.0693 - val_loss: 0.1604 - val_mean_absolute_error: 0.0779\n",
      "Epoch 16/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1203 - mean_absolute_error: 0.0660 - val_loss: 0.1510 - val_mean_absolute_error: 0.0745\n",
      "Epoch 17/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.1123 - mean_absolute_error: 0.0630 - val_loss: 0.1424 - val_mean_absolute_error: 0.0717\n",
      "Epoch 18/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.1049 - mean_absolute_error: 0.0603 - val_loss: 0.1345 - val_mean_absolute_error: 0.0692\n",
      "Epoch 19/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0986 - mean_absolute_error: 0.0579 - val_loss: 0.1274 - val_mean_absolute_error: 0.0669\n",
      "Epoch 20/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0927 - mean_absolute_error: 0.0557 - val_loss: 0.1211 - val_mean_absolute_error: 0.0649\n",
      "Epoch 21/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0874 - mean_absolute_error: 0.0538 - val_loss: 0.1153 - val_mean_absolute_error: 0.0630\n",
      "Epoch 22/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0826 - mean_absolute_error: 0.0519 - val_loss: 0.1099 - val_mean_absolute_error: 0.0612\n",
      "Epoch 23/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0782 - mean_absolute_error: 0.0502 - val_loss: 0.1050 - val_mean_absolute_error: 0.0596\n",
      "Epoch 24/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0742 - mean_absolute_error: 0.0487 - val_loss: 0.1004 - val_mean_absolute_error: 0.0582\n",
      "Epoch 25/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0706 - mean_absolute_error: 0.0473 - val_loss: 0.0963 - val_mean_absolute_error: 0.0568\n",
      "Epoch 26/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0672 - mean_absolute_error: 0.0460 - val_loss: 0.0918 - val_mean_absolute_error: 0.0553\n",
      "Epoch 27/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0640 - mean_absolute_error: 0.0447 - val_loss: 0.0878 - val_mean_absolute_error: 0.0539\n",
      "Epoch 28/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.0610 - mean_absolute_error: 0.0436 - val_loss: 0.0842 - val_mean_absolute_error: 0.0527\n",
      "Epoch 29/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0582 - mean_absolute_error: 0.0424 - val_loss: 0.0808 - val_mean_absolute_error: 0.0514\n",
      "Epoch 30/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0557 - mean_absolute_error: 0.0414 - val_loss: 0.0778 - val_mean_absolute_error: 0.0504\n",
      "Epoch 31/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0533 - mean_absolute_error: 0.0404 - val_loss: 0.0751 - val_mean_absolute_error: 0.0494\n",
      "Epoch 32/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0512 - mean_absolute_error: 0.0395 - val_loss: 0.0724 - val_mean_absolute_error: 0.0483\n",
      "Epoch 33/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0491 - mean_absolute_error: 0.0386 - val_loss: 0.0699 - val_mean_absolute_error: 0.0474\n",
      "Epoch 34/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0472 - mean_absolute_error: 0.0378 - val_loss: 0.0674 - val_mean_absolute_error: 0.0464\n",
      "Epoch 35/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0454 - mean_absolute_error: 0.0370 - val_loss: 0.0652 - val_mean_absolute_error: 0.0456\n",
      "Epoch 36/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0437 - mean_absolute_error: 0.0362 - val_loss: 0.0632 - val_mean_absolute_error: 0.0447\n",
      "Epoch 37/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0420 - mean_absolute_error: 0.0355 - val_loss: 0.0607 - val_mean_absolute_error: 0.0436\n",
      "Epoch 38/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0404 - mean_absolute_error: 0.0347 - val_loss: 0.0589 - val_mean_absolute_error: 0.0429\n",
      "Epoch 39/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0390 - mean_absolute_error: 0.0340 - val_loss: 0.0571 - val_mean_absolute_error: 0.0422\n",
      "Epoch 40/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0376 - mean_absolute_error: 0.0333 - val_loss: 0.0554 - val_mean_absolute_error: 0.0414\n",
      "Epoch 41/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0364 - mean_absolute_error: 0.0327 - val_loss: 0.0539 - val_mean_absolute_error: 0.0408\n",
      "Epoch 42/200\n",
      "386/386 [==============================] - 0s 57us/sample - loss: 0.0352 - mean_absolute_error: 0.0321 - val_loss: 0.0523 - val_mean_absolute_error: 0.0401\n",
      "Epoch 43/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0340 - mean_absolute_error: 0.0315 - val_loss: 0.0505 - val_mean_absolute_error: 0.0393\n",
      "Epoch 44/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.0329 - mean_absolute_error: 0.0310 - val_loss: 0.0492 - val_mean_absolute_error: 0.0386\n",
      "Epoch 45/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0319 - mean_absolute_error: 0.0304 - val_loss: 0.0478 - val_mean_absolute_error: 0.0380\n",
      "Epoch 46/200\n",
      "386/386 [==============================] - 0s 55us/sample - loss: 0.0309 - mean_absolute_error: 0.0299 - val_loss: 0.0466 - val_mean_absolute_error: 0.0375\n",
      "Epoch 47/200\n",
      "386/386 [==============================] - 0s 57us/sample - loss: 0.0299 - mean_absolute_error: 0.0293 - val_loss: 0.0455 - val_mean_absolute_error: 0.0369\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386/386 [==============================] - 0s 65us/sample - loss: 0.0290 - mean_absolute_error: 0.0288 - val_loss: 0.0444 - val_mean_absolute_error: 0.0364\n",
      "Epoch 49/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0281 - mean_absolute_error: 0.0283 - val_loss: 0.0431 - val_mean_absolute_error: 0.0357\n",
      "Epoch 50/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0273 - mean_absolute_error: 0.0278 - val_loss: 0.0418 - val_mean_absolute_error: 0.0351\n",
      "Epoch 51/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0265 - mean_absolute_error: 0.0273 - val_loss: 0.0407 - val_mean_absolute_error: 0.0345\n",
      "Epoch 52/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0257 - mean_absolute_error: 0.0269 - val_loss: 0.0395 - val_mean_absolute_error: 0.0338\n",
      "Epoch 53/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0249 - mean_absolute_error: 0.0265 - val_loss: 0.0387 - val_mean_absolute_error: 0.0334\n",
      "Epoch 54/200\n",
      "386/386 [==============================] - 0s 45us/sample - loss: 0.0242 - mean_absolute_error: 0.0260 - val_loss: 0.0377 - val_mean_absolute_error: 0.0329\n",
      "Epoch 55/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0236 - mean_absolute_error: 0.0256 - val_loss: 0.0368 - val_mean_absolute_error: 0.0324\n",
      "Epoch 56/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0229 - mean_absolute_error: 0.0252 - val_loss: 0.0356 - val_mean_absolute_error: 0.0317\n",
      "Epoch 57/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0222 - mean_absolute_error: 0.0247 - val_loss: 0.0348 - val_mean_absolute_error: 0.0312\n",
      "Epoch 58/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0216 - mean_absolute_error: 0.0243 - val_loss: 0.0339 - val_mean_absolute_error: 0.0306\n",
      "Epoch 59/200\n",
      "386/386 [==============================] - 0s 53us/sample - loss: 0.0210 - mean_absolute_error: 0.0239 - val_loss: 0.0330 - val_mean_absolute_error: 0.0301\n",
      "Epoch 60/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0205 - mean_absolute_error: 0.0236 - val_loss: 0.0323 - val_mean_absolute_error: 0.0297\n",
      "Epoch 61/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0199 - mean_absolute_error: 0.0232 - val_loss: 0.0316 - val_mean_absolute_error: 0.0293\n",
      "Epoch 62/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0194 - mean_absolute_error: 0.0228 - val_loss: 0.0308 - val_mean_absolute_error: 0.0288\n",
      "Epoch 63/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0189 - mean_absolute_error: 0.0225 - val_loss: 0.0302 - val_mean_absolute_error: 0.0284\n",
      "Epoch 64/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0184 - mean_absolute_error: 0.0221 - val_loss: 0.0295 - val_mean_absolute_error: 0.0280\n",
      "Epoch 65/200\n",
      "386/386 [==============================] - 0s 48us/sample - loss: 0.0180 - mean_absolute_error: 0.0218 - val_loss: 0.0289 - val_mean_absolute_error: 0.0276\n",
      "Epoch 66/200\n",
      "386/386 [==============================] - 0s 50us/sample - loss: 0.0175 - mean_absolute_error: 0.0214 - val_loss: 0.0284 - val_mean_absolute_error: 0.0272\n",
      "Epoch 67/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0171 - mean_absolute_error: 0.0211 - val_loss: 0.0278 - val_mean_absolute_error: 0.0269\n",
      "Epoch 68/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0167 - mean_absolute_error: 0.0208 - val_loss: 0.0272 - val_mean_absolute_error: 0.0265\n",
      "Epoch 69/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0163 - mean_absolute_error: 0.0205 - val_loss: 0.0267 - val_mean_absolute_error: 0.0261\n",
      "Epoch 70/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0159 - mean_absolute_error: 0.0202 - val_loss: 0.0261 - val_mean_absolute_error: 0.0258\n",
      "Epoch 71/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0155 - mean_absolute_error: 0.0199 - val_loss: 0.0256 - val_mean_absolute_error: 0.0254\n",
      "Epoch 72/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0151 - mean_absolute_error: 0.0196 - val_loss: 0.0252 - val_mean_absolute_error: 0.0251\n",
      "Epoch 73/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0148 - mean_absolute_error: 0.0194 - val_loss: 0.0247 - val_mean_absolute_error: 0.0248\n",
      "Epoch 74/200\n",
      "386/386 [==============================] - 0s 37us/sample - loss: 0.0145 - mean_absolute_error: 0.0191 - val_loss: 0.0243 - val_mean_absolute_error: 0.0245\n",
      "Epoch 75/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0141 - mean_absolute_error: 0.0188 - val_loss: 0.0239 - val_mean_absolute_error: 0.0242\n",
      "Epoch 76/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0138 - mean_absolute_error: 0.0186 - val_loss: 0.0234 - val_mean_absolute_error: 0.0239\n",
      "Epoch 77/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0135 - mean_absolute_error: 0.0183 - val_loss: 0.0228 - val_mean_absolute_error: 0.0234\n",
      "Epoch 78/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0132 - mean_absolute_error: 0.0181 - val_loss: 0.0223 - val_mean_absolute_error: 0.0231\n",
      "Epoch 79/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0129 - mean_absolute_error: 0.0178 - val_loss: 0.0220 - val_mean_absolute_error: 0.0228\n",
      "Epoch 80/200\n",
      "386/386 [==============================] - 0s 37us/sample - loss: 0.0126 - mean_absolute_error: 0.0176 - val_loss: 0.0216 - val_mean_absolute_error: 0.0225\n",
      "Epoch 81/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0123 - mean_absolute_error: 0.0174 - val_loss: 0.0212 - val_mean_absolute_error: 0.0222\n",
      "Epoch 82/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0121 - mean_absolute_error: 0.0172 - val_loss: 0.0208 - val_mean_absolute_error: 0.0219\n",
      "Epoch 83/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0118 - mean_absolute_error: 0.0170 - val_loss: 0.0204 - val_mean_absolute_error: 0.0216\n",
      "Epoch 84/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0116 - mean_absolute_error: 0.0168 - val_loss: 0.0200 - val_mean_absolute_error: 0.0213\n",
      "Epoch 85/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0113 - mean_absolute_error: 0.0166 - val_loss: 0.0197 - val_mean_absolute_error: 0.0211\n",
      "Epoch 86/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0111 - mean_absolute_error: 0.0164 - val_loss: 0.0193 - val_mean_absolute_error: 0.0208\n",
      "Epoch 87/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0109 - mean_absolute_error: 0.0161 - val_loss: 0.0190 - val_mean_absolute_error: 0.0206\n",
      "Epoch 88/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0106 - mean_absolute_error: 0.0160 - val_loss: 0.0187 - val_mean_absolute_error: 0.0203\n",
      "Epoch 89/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0104 - mean_absolute_error: 0.0158 - val_loss: 0.0184 - val_mean_absolute_error: 0.0201\n",
      "Epoch 90/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0102 - mean_absolute_error: 0.0156 - val_loss: 0.0180 - val_mean_absolute_error: 0.0198\n",
      "Epoch 91/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0100 - mean_absolute_error: 0.0154 - val_loss: 0.0177 - val_mean_absolute_error: 0.0195\n",
      "Epoch 92/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0098 - mean_absolute_error: 0.0152 - val_loss: 0.0174 - val_mean_absolute_error: 0.0193\n",
      "Epoch 93/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0096 - mean_absolute_error: 0.0151 - val_loss: 0.0172 - val_mean_absolute_error: 0.0191\n",
      "Epoch 94/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0095 - mean_absolute_error: 0.0149 - val_loss: 0.0169 - val_mean_absolute_error: 0.0189\n",
      "Epoch 95/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0093 - mean_absolute_error: 0.0147 - val_loss: 0.0167 - val_mean_absolute_error: 0.0187\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0091 - mean_absolute_error: 0.0146 - val_loss: 0.0164 - val_mean_absolute_error: 0.0185\n",
      "Epoch 97/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0089 - mean_absolute_error: 0.0144 - val_loss: 0.0162 - val_mean_absolute_error: 0.0183\n",
      "Epoch 98/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0088 - mean_absolute_error: 0.0142 - val_loss: 0.0159 - val_mean_absolute_error: 0.0181\n",
      "Epoch 99/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0086 - mean_absolute_error: 0.0141 - val_loss: 0.0157 - val_mean_absolute_error: 0.0179\n",
      "Epoch 100/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0085 - mean_absolute_error: 0.0139 - val_loss: 0.0155 - val_mean_absolute_error: 0.0178\n",
      "Epoch 101/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0083 - mean_absolute_error: 0.0138 - val_loss: 0.0153 - val_mean_absolute_error: 0.0176\n",
      "Epoch 102/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0082 - mean_absolute_error: 0.0136 - val_loss: 0.0151 - val_mean_absolute_error: 0.0174\n",
      "Epoch 103/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0080 - mean_absolute_error: 0.0135 - val_loss: 0.0149 - val_mean_absolute_error: 0.0172\n",
      "Epoch 104/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0079 - mean_absolute_error: 0.0134 - val_loss: 0.0147 - val_mean_absolute_error: 0.0171\n",
      "Epoch 105/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0078 - mean_absolute_error: 0.0132 - val_loss: 0.0145 - val_mean_absolute_error: 0.0169\n",
      "Epoch 106/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0076 - mean_absolute_error: 0.0131 - val_loss: 0.0143 - val_mean_absolute_error: 0.0167\n",
      "Epoch 107/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0075 - mean_absolute_error: 0.0130 - val_loss: 0.0141 - val_mean_absolute_error: 0.0166\n",
      "Epoch 108/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0074 - mean_absolute_error: 0.0129 - val_loss: 0.0139 - val_mean_absolute_error: 0.0164\n",
      "Epoch 109/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0073 - mean_absolute_error: 0.0127 - val_loss: 0.0137 - val_mean_absolute_error: 0.0162\n",
      "Epoch 110/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0071 - mean_absolute_error: 0.0126 - val_loss: 0.0135 - val_mean_absolute_error: 0.0160\n",
      "Epoch 111/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0070 - mean_absolute_error: 0.0125 - val_loss: 0.0133 - val_mean_absolute_error: 0.0158\n",
      "Epoch 112/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0069 - mean_absolute_error: 0.0124 - val_loss: 0.0132 - val_mean_absolute_error: 0.0157\n",
      "Epoch 113/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0068 - mean_absolute_error: 0.0123 - val_loss: 0.0130 - val_mean_absolute_error: 0.0156\n",
      "Epoch 114/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0067 - mean_absolute_error: 0.0122 - val_loss: 0.0128 - val_mean_absolute_error: 0.0154\n",
      "Epoch 115/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0066 - mean_absolute_error: 0.0121 - val_loss: 0.0127 - val_mean_absolute_error: 0.0153\n",
      "Epoch 116/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0065 - mean_absolute_error: 0.0120 - val_loss: 0.0124 - val_mean_absolute_error: 0.0151\n",
      "Epoch 117/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0064 - mean_absolute_error: 0.0119 - val_loss: 0.0123 - val_mean_absolute_error: 0.0149\n",
      "Epoch 118/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0063 - mean_absolute_error: 0.0118 - val_loss: 0.0121 - val_mean_absolute_error: 0.0148\n",
      "Epoch 119/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0062 - mean_absolute_error: 0.0117 - val_loss: 0.0120 - val_mean_absolute_error: 0.0146\n",
      "Epoch 120/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0061 - mean_absolute_error: 0.0116 - val_loss: 0.0118 - val_mean_absolute_error: 0.0145\n",
      "Epoch 121/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0060 - mean_absolute_error: 0.0115 - val_loss: 0.0117 - val_mean_absolute_error: 0.0144\n",
      "Epoch 122/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0059 - mean_absolute_error: 0.0114 - val_loss: 0.0115 - val_mean_absolute_error: 0.0142\n",
      "Epoch 123/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0058 - mean_absolute_error: 0.0114 - val_loss: 0.0114 - val_mean_absolute_error: 0.0141\n",
      "Epoch 124/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0057 - mean_absolute_error: 0.0113 - val_loss: 0.0112 - val_mean_absolute_error: 0.0140\n",
      "Epoch 125/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0057 - mean_absolute_error: 0.0112 - val_loss: 0.0111 - val_mean_absolute_error: 0.0139\n",
      "Epoch 126/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0056 - mean_absolute_error: 0.0111 - val_loss: 0.0110 - val_mean_absolute_error: 0.0138\n",
      "Epoch 127/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0055 - mean_absolute_error: 0.0110 - val_loss: 0.0109 - val_mean_absolute_error: 0.0137\n",
      "Epoch 128/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0054 - mean_absolute_error: 0.0109 - val_loss: 0.0108 - val_mean_absolute_error: 0.0136\n",
      "Epoch 129/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0054 - mean_absolute_error: 0.0109 - val_loss: 0.0107 - val_mean_absolute_error: 0.0134\n",
      "Epoch 130/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0053 - mean_absolute_error: 0.0108 - val_loss: 0.0106 - val_mean_absolute_error: 0.0133\n",
      "Epoch 131/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0052 - mean_absolute_error: 0.0107 - val_loss: 0.0105 - val_mean_absolute_error: 0.0133\n",
      "Epoch 132/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0051 - mean_absolute_error: 0.0106 - val_loss: 0.0104 - val_mean_absolute_error: 0.0132\n",
      "Epoch 133/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0051 - mean_absolute_error: 0.0106 - val_loss: 0.0103 - val_mean_absolute_error: 0.0131\n",
      "Epoch 134/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0050 - mean_absolute_error: 0.0105 - val_loss: 0.0102 - val_mean_absolute_error: 0.0130\n",
      "Epoch 135/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0050 - mean_absolute_error: 0.0104 - val_loss: 0.0100 - val_mean_absolute_error: 0.0129\n",
      "Epoch 136/200\n",
      "386/386 [==============================] - 0s 37us/sample - loss: 0.0049 - mean_absolute_error: 0.0104 - val_loss: 0.0099 - val_mean_absolute_error: 0.0128\n",
      "Epoch 137/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0048 - mean_absolute_error: 0.0103 - val_loss: 0.0099 - val_mean_absolute_error: 0.0127\n",
      "Epoch 138/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0048 - mean_absolute_error: 0.0102 - val_loss: 0.0098 - val_mean_absolute_error: 0.0126\n",
      "Epoch 139/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0047 - mean_absolute_error: 0.0102 - val_loss: 0.0097 - val_mean_absolute_error: 0.0125\n",
      "Epoch 140/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0047 - mean_absolute_error: 0.0101 - val_loss: 0.0096 - val_mean_absolute_error: 0.0124\n",
      "Epoch 141/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0046 - mean_absolute_error: 0.0101 - val_loss: 0.0095 - val_mean_absolute_error: 0.0123\n",
      "Epoch 142/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0045 - mean_absolute_error: 0.0100 - val_loss: 0.0094 - val_mean_absolute_error: 0.0123\n",
      "Epoch 143/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0045 - mean_absolute_error: 0.0099 - val_loss: 0.0094 - val_mean_absolute_error: 0.0122\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0044 - mean_absolute_error: 0.0099 - val_loss: 0.0093 - val_mean_absolute_error: 0.0121\n",
      "Epoch 145/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0044 - mean_absolute_error: 0.0098 - val_loss: 0.0092 - val_mean_absolute_error: 0.0120\n",
      "Epoch 146/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0043 - mean_absolute_error: 0.0098 - val_loss: 0.0091 - val_mean_absolute_error: 0.0120\n",
      "Epoch 147/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0043 - mean_absolute_error: 0.0097 - val_loss: 0.0091 - val_mean_absolute_error: 0.0119\n",
      "Epoch 148/200\n",
      "386/386 [==============================] - 0s 63us/sample - loss: 0.0042 - mean_absolute_error: 0.0097 - val_loss: 0.0090 - val_mean_absolute_error: 0.0118\n",
      "Epoch 149/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0042 - mean_absolute_error: 0.0096 - val_loss: 0.0089 - val_mean_absolute_error: 0.0118\n",
      "Epoch 150/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0041 - mean_absolute_error: 0.0096 - val_loss: 0.0088 - val_mean_absolute_error: 0.0117\n",
      "Epoch 151/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0041 - mean_absolute_error: 0.0095 - val_loss: 0.0088 - val_mean_absolute_error: 0.0116\n",
      "Epoch 152/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0040 - mean_absolute_error: 0.0095 - val_loss: 0.0087 - val_mean_absolute_error: 0.0115\n",
      "Epoch 153/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0040 - mean_absolute_error: 0.0094 - val_loss: 0.0086 - val_mean_absolute_error: 0.0115\n",
      "Epoch 154/200\n",
      "386/386 [==============================] - 0s 54us/sample - loss: 0.0040 - mean_absolute_error: 0.0094 - val_loss: 0.0085 - val_mean_absolute_error: 0.0114\n",
      "Epoch 155/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0039 - mean_absolute_error: 0.0093 - val_loss: 0.0084 - val_mean_absolute_error: 0.0113\n",
      "Epoch 156/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.0039 - mean_absolute_error: 0.0093 - val_loss: 0.0083 - val_mean_absolute_error: 0.0112\n",
      "Epoch 157/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0038 - mean_absolute_error: 0.0092 - val_loss: 0.0083 - val_mean_absolute_error: 0.0111\n",
      "Epoch 158/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0038 - mean_absolute_error: 0.0092 - val_loss: 0.0082 - val_mean_absolute_error: 0.0111\n",
      "Epoch 159/200\n",
      "386/386 [==============================] - 0s 57us/sample - loss: 0.0038 - mean_absolute_error: 0.0091 - val_loss: 0.0082 - val_mean_absolute_error: 0.0110\n",
      "Epoch 160/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0037 - mean_absolute_error: 0.0091 - val_loss: 0.0080 - val_mean_absolute_error: 0.0109\n",
      "Epoch 161/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0037 - mean_absolute_error: 0.0091 - val_loss: 0.0080 - val_mean_absolute_error: 0.0109\n",
      "Epoch 162/200\n",
      "386/386 [==============================] - 0s 52us/sample - loss: 0.0036 - mean_absolute_error: 0.0090 - val_loss: 0.0079 - val_mean_absolute_error: 0.0108\n",
      "Epoch 163/200\n",
      "386/386 [==============================] - 0s 49us/sample - loss: 0.0036 - mean_absolute_error: 0.0090 - val_loss: 0.0079 - val_mean_absolute_error: 0.0107\n",
      "Epoch 164/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0036 - mean_absolute_error: 0.0089 - val_loss: 0.0078 - val_mean_absolute_error: 0.0107\n",
      "Epoch 165/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0035 - mean_absolute_error: 0.0089 - val_loss: 0.0078 - val_mean_absolute_error: 0.0106\n",
      "Epoch 166/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0035 - mean_absolute_error: 0.0089 - val_loss: 0.0077 - val_mean_absolute_error: 0.0106\n",
      "Epoch 167/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0035 - mean_absolute_error: 0.0088 - val_loss: 0.0077 - val_mean_absolute_error: 0.0105\n",
      "Epoch 168/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0034 - mean_absolute_error: 0.0088 - val_loss: 0.0076 - val_mean_absolute_error: 0.0105\n",
      "Epoch 169/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.0034 - mean_absolute_error: 0.0087 - val_loss: 0.0076 - val_mean_absolute_error: 0.0104\n",
      "Epoch 170/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0034 - mean_absolute_error: 0.0087 - val_loss: 0.0075 - val_mean_absolute_error: 0.0104\n",
      "Epoch 171/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0033 - mean_absolute_error: 0.0087 - val_loss: 0.0075 - val_mean_absolute_error: 0.0103\n",
      "Epoch 172/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0033 - mean_absolute_error: 0.0086 - val_loss: 0.0074 - val_mean_absolute_error: 0.0103\n",
      "Epoch 173/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0033 - mean_absolute_error: 0.0086 - val_loss: 0.0074 - val_mean_absolute_error: 0.0102\n",
      "Epoch 174/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0033 - mean_absolute_error: 0.0086 - val_loss: 0.0073 - val_mean_absolute_error: 0.0102\n",
      "Epoch 175/200\n",
      "386/386 [==============================] - 0s 45us/sample - loss: 0.0032 - mean_absolute_error: 0.0085 - val_loss: 0.0073 - val_mean_absolute_error: 0.0101\n",
      "Epoch 176/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0032 - mean_absolute_error: 0.0085 - val_loss: 0.0072 - val_mean_absolute_error: 0.0101\n",
      "Epoch 177/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0032 - mean_absolute_error: 0.0085 - val_loss: 0.0072 - val_mean_absolute_error: 0.0100\n",
      "Epoch 178/200\n",
      "386/386 [==============================] - 0s 43us/sample - loss: 0.0031 - mean_absolute_error: 0.0084 - val_loss: 0.0071 - val_mean_absolute_error: 0.0100\n",
      "Epoch 179/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0031 - mean_absolute_error: 0.0084 - val_loss: 0.0071 - val_mean_absolute_error: 0.0100\n",
      "Epoch 180/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0031 - mean_absolute_error: 0.0084 - val_loss: 0.0071 - val_mean_absolute_error: 0.0099\n",
      "Epoch 181/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0031 - mean_absolute_error: 0.0084 - val_loss: 0.0070 - val_mean_absolute_error: 0.0099\n",
      "Epoch 182/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0030 - mean_absolute_error: 0.0083 - val_loss: 0.0069 - val_mean_absolute_error: 0.0098\n",
      "Epoch 183/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0030 - mean_absolute_error: 0.0083 - val_loss: 0.0069 - val_mean_absolute_error: 0.0097\n",
      "Epoch 184/200\n",
      "386/386 [==============================] - 0s 36us/sample - loss: 0.0030 - mean_absolute_error: 0.0083 - val_loss: 0.0069 - val_mean_absolute_error: 0.0097\n",
      "Epoch 185/200\n",
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0030 - mean_absolute_error: 0.0082 - val_loss: 0.0068 - val_mean_absolute_error: 0.0097\n",
      "Epoch 186/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0029 - mean_absolute_error: 0.0082 - val_loss: 0.0068 - val_mean_absolute_error: 0.0096\n",
      "Epoch 187/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0029 - mean_absolute_error: 0.0082 - val_loss: 0.0068 - val_mean_absolute_error: 0.0096\n",
      "Epoch 188/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0029 - mean_absolute_error: 0.0081 - val_loss: 0.0067 - val_mean_absolute_error: 0.0095\n",
      "Epoch 189/200\n",
      "386/386 [==============================] - 0s 43us/sample - loss: 0.0029 - mean_absolute_error: 0.0081 - val_loss: 0.0067 - val_mean_absolute_error: 0.0095\n",
      "Epoch 190/200\n",
      "386/386 [==============================] - 0s 40us/sample - loss: 0.0029 - mean_absolute_error: 0.0081 - val_loss: 0.0066 - val_mean_absolute_error: 0.0095\n",
      "Epoch 191/200\n",
      "386/386 [==============================] - 0s 46us/sample - loss: 0.0028 - mean_absolute_error: 0.0081 - val_loss: 0.0066 - val_mean_absolute_error: 0.0094\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386/386 [==============================] - 0s 38us/sample - loss: 0.0028 - mean_absolute_error: 0.0080 - val_loss: 0.0066 - val_mean_absolute_error: 0.0094\n",
      "Epoch 193/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0028 - mean_absolute_error: 0.0080 - val_loss: 0.0065 - val_mean_absolute_error: 0.0094\n",
      "Epoch 194/200\n",
      "386/386 [==============================] - 0s 47us/sample - loss: 0.0028 - mean_absolute_error: 0.0080 - val_loss: 0.0065 - val_mean_absolute_error: 0.0093\n",
      "Epoch 195/200\n",
      "386/386 [==============================] - 0s 39us/sample - loss: 0.0028 - mean_absolute_error: 0.0080 - val_loss: 0.0065 - val_mean_absolute_error: 0.0093\n",
      "Epoch 196/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0027 - mean_absolute_error: 0.0079 - val_loss: 0.0064 - val_mean_absolute_error: 0.0093\n",
      "Epoch 197/200\n",
      "386/386 [==============================] - 0s 42us/sample - loss: 0.0027 - mean_absolute_error: 0.0079 - val_loss: 0.0064 - val_mean_absolute_error: 0.0092\n",
      "Epoch 198/200\n",
      "386/386 [==============================] - 0s 44us/sample - loss: 0.0027 - mean_absolute_error: 0.0079 - val_loss: 0.0064 - val_mean_absolute_error: 0.0092\n",
      "Epoch 199/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0027 - mean_absolute_error: 0.0079 - val_loss: 0.0063 - val_mean_absolute_error: 0.0091\n",
      "Epoch 200/200\n",
      "386/386 [==============================] - 0s 41us/sample - loss: 0.0027 - mean_absolute_error: 0.0078 - val_loss: 0.0063 - val_mean_absolute_error: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15bbc4bb608>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_data, validation_split=0.2, epochs=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
